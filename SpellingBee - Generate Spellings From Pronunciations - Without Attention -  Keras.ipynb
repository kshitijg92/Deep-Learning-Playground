{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Bee - Sequence Modeling using LSTM - Keras\n",
    "\n",
    "In the notebook we will explore how to correctly spell words using their phonetic pronunciations, i.e. we will take the pronunciation of a word, and then try to spell it correctly.\n",
    "\n",
    "We will be using Recurrent Neural Networks for this task (in the following notebook, we will add attention modeling to it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "from PIL import Image\n",
    "import gc,re\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Embedding, Reshape, RepeatVector, \\\n",
    "                         UpSampling2D, Flatten, Dropout, LSTM, TimeDistributed, Bidirectional\n",
    "#from keras.layers.merge import Add\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from importlib import reload\n",
    "from keras import backend as K\n",
    "from keras.datasets import imdb\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import bcolz\n",
    "from IPython.display import FileLink\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from keras import metrics\n",
    "from scipy.misc import imsave\n",
    "import imageio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "\n",
    "The data can be obtained from here : http://www.speech.cs.cmu.edu/cgi-bin/cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/spellingbee/cmudict-0.7b'\n",
    "\n",
    "f = open(PATH, encoding='latin1')\n",
    "lines = []\n",
    "\n",
    "for line in f:    \n",
    "    \n",
    "    #add to lines if starting letter is an alphabet\n",
    "    if re.match('^[A-Z]', line):\n",
    "        lines.append(line.strip().split(\" \"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133779"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABANTO', '', 'AH0', 'B', 'AE1', 'N', 'T', 'OW0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the data that we have. Each sound/word is followed by its phonetic pronunciation and we have almost 134k such words.\n",
    "\n",
    "Each phonetic pronunciation is a sequence of phonemes. *Note* that the vowels end in integers. These integers denote the stress levels.\n",
    "\n",
    "Also, in our list above, we have the word/sound followed by a space and then followed by the corresponding phoneme sequence. Let us split and store word/sound and their pronunciations properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_data=[]\n",
    "for line in lines:\n",
    "    word = line[0]\n",
    "    phonemes = line[2:len(line)]\n",
    "    lines_data.append((word,phonemes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ABANTO', ['AH0', 'B', 'AE1', 'N', 'T', 'OW0']),\n",
       " ('ZYWICKI', ['Z', 'IH0', 'W', 'IH1', 'K', 'IY0']))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_data[55], lines_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us get all the individual phonemes that are present in the dataset\n",
    "\n",
    "We will also add an **_** to the list which helps in zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = []\n",
    "\n",
    "for w,ps in lines_data:\n",
    "    for p in ps:\n",
    "        phonemes.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = ['_'] + sorted(set(phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', 'AA0', 'AA1', 'AA2', 'AE0', 'AE1', 'AE2', 'AH0', 'AH1', 'AH2']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that we have a total of 70 unique phonemes in our dataset (including the _ that we added for reference to zero-padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with every NLP task, we need to assign indices to letters and then work with those indices. So now we will be creating two dictionaries which will keep track of phonemes to indices and letters to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2i = {v : k for k,v in enumerate(phonemes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA0': 1,\n",
       " 'AA1': 2,\n",
       " 'AA2': 3,\n",
       " 'AE0': 4,\n",
       " 'AE1': 5,\n",
       " 'AE2': 6,\n",
       " 'AH0': 7,\n",
       " 'AH1': 8,\n",
       " 'AH2': 9,\n",
       " 'AO0': 10,\n",
       " 'AO1': 11,\n",
       " 'AO2': 12,\n",
       " 'AW0': 13,\n",
       " 'AW1': 14,\n",
       " 'AW2': 15,\n",
       " 'AY0': 16,\n",
       " 'AY1': 17,\n",
       " 'AY2': 18,\n",
       " 'B': 19,\n",
       " 'CH': 20,\n",
       " 'D': 21,\n",
       " 'DH': 22,\n",
       " 'EH0': 23,\n",
       " 'EH1': 24,\n",
       " 'EH2': 25,\n",
       " 'ER0': 26,\n",
       " 'ER1': 27,\n",
       " 'ER2': 28,\n",
       " 'EY0': 29,\n",
       " 'EY1': 30,\n",
       " 'EY2': 31,\n",
       " 'F': 32,\n",
       " 'G': 33,\n",
       " 'HH': 34,\n",
       " 'IH0': 35,\n",
       " 'IH1': 36,\n",
       " 'IH2': 37,\n",
       " 'IY0': 38,\n",
       " 'IY1': 39,\n",
       " 'IY2': 40,\n",
       " 'JH': 41,\n",
       " 'K': 42,\n",
       " 'L': 43,\n",
       " 'M': 44,\n",
       " 'N': 45,\n",
       " 'NG': 46,\n",
       " 'OW0': 47,\n",
       " 'OW1': 48,\n",
       " 'OW2': 49,\n",
       " 'OY0': 50,\n",
       " 'OY1': 51,\n",
       " 'OY2': 52,\n",
       " 'P': 53,\n",
       " 'R': 54,\n",
       " 'S': 55,\n",
       " 'SH': 56,\n",
       " 'T': 57,\n",
       " 'TH': 58,\n",
       " 'UH0': 59,\n",
       " 'UH1': 60,\n",
       " 'UH2': 61,\n",
       " 'UW0': 62,\n",
       " 'UW1': 63,\n",
       " 'UW2': 64,\n",
       " 'V': 65,\n",
       " 'W': 66,\n",
       " 'Y': 67,\n",
       " 'Z': 68,\n",
       " 'ZH': 69,\n",
       " '_': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = \"_abcdefghijklmnopqrstuvwxyz*\"   # This also includes _ which we added earlier and * which will become \n",
    "                                           # clear later.\n",
    "l2i = {v : k for k,v in enumerate(letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*': 27,\n",
       " '_': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we a dictionary which maps phonemes to indices, we can go to our lines_data and replace each phoneme by its index. \n",
    "\n",
    "We will also filter our dataset to only include words of length 5 to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length_word = 5\n",
    "max_length_word = 15\n",
    "\n",
    "pronunciation_dictionary = {}\n",
    "\n",
    "for w,ps in lines_data:\n",
    "    \n",
    "    if (min_length_word <= len(w) <= max_length_word) and re.match(\"^[A-Z]+$\", w):\n",
    "        temp = []\n",
    "        for p in ps:\n",
    "            temp.append(p2i[p])\n",
    "        pronunciation_dictionary[w.lower()] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108006"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pronunciation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([7, 19, 5, 45, 57, 47], ('ABANTO', ['AH0', 'B', 'AE1', 'N', 'T', 'OW0']))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciation_dictionary['abanto'], lines_data[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have converted each word into indices of phonemes, we can proceed further. We also see that our dataset has reduced to almost 108k words.\n",
    "\n",
    "As with most other NLP tasks, we will have an embedding layer as our first layer which would embed each phoneme into some higher dimensional space. As such, we first need to find out the maximum phoneme sequence which is present in our dataset. We will then use that to pad the other sequences so that every phoneme sequence is of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_phoneme_sequence = max([len(v) for k,v in pronunciation_dictionary.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_phoneme_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know what there exists at least one word in our dataset whose phoneme sequence is almost 16 phonemes long!\n",
    "\n",
    "Now time for zero padding. We need to pad phoneme sequences (which have length <16) with zeros. Lets do it ourselves here instead of using the inbuilt Keras method.\n",
    "\n",
    "Also, our current task involves predicting the spellings using these phonemes. So our labels are words reach of maximum length 15. We also need to pad words of length less than 15 then.\n",
    "\n",
    "We will start with already zero matrices of the required sizes. For each row, we will fill the first few columns, as required, and the rest will remain zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.random.permutation(list(pronunciation_dictionary.keys()))\n",
    "n = len(words)\n",
    "\n",
    "input_ = np.zeros((n,max_phoneme_sequence), np.int32)  # inputs are phonemes of max length 16\n",
    "labels_ = np.zeros((n, max_length_word) , np.int32)     # outputs are words of max length 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(words):\n",
    "    \n",
    "    # fill those indices of input_ which are non-zero \n",
    "    for j, p in enumerate(pronunciation_dictionary[k]):\n",
    "        input_[i][j] = p\n",
    "    \n",
    "    # fill those indices of labels_ which are non-zero\n",
    "    for j,letter in enumerate(k):\n",
    "        labels_[i][j] = l2i[letter]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108006, 16), (108006, 15))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_.shape, labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([54, 36, 55, 42, 35, 46,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32),\n",
       " array([18,  9, 19, 11,  9, 14,  7,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_[55], labels_[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us split our data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_train, input_test, labels_train, labels_test) = train_test_split(input_, labels_, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97205, 16), (97205, 15), (10801, 16), (10801, 15))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape, labels_train.shape, input_test.shape , labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reiterate, let us check what is the unique number of phonemes, and unique number of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_unique_phonemes = len(phonemes)\n",
    "n_unique_letters = len(letters)\n",
    "\n",
    "n_unique_phonemes, n_unique_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "\n",
    "Now we have set up the stage for creating our model.\n",
    "\n",
    "References : https://keras.io/layers/recurrent/#lstm\n",
    "\n",
    "References : https://keras.io/layers/wrappers/\n",
    "\n",
    "References : https://keras.io/layers/core/#repeatvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a function which we defined to create cleaner code. Note that return_sequences in LSTM means whether to return the last output in an output of sequences (if set to False) or whether to return the whole output_of_sequences (if set to True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn(return_sequences=True):\n",
    "    return LSTM(240, dropout=0.1, recurrent_dropout=0.1, return_sequences=return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 16, 120)           8400      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 16, 480)           693120    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 240)               692160    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 15, 240)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 15, 240)           461760    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 15, 240)           461760    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 15, 28)            6748      \n",
      "=================================================================\n",
      "Total params: 2,323,948\n",
      "Trainable params: 2,323,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(max_phoneme_sequence,))\n",
    "x = Embedding(n_unique_phonemes, 120)(inp)\n",
    "\n",
    "#Encoder\n",
    "\n",
    "x = Bidirectional(get_rnn())(x)\n",
    "x = get_rnn(False)(x)\n",
    "\n",
    "x = RepeatVector(max_length_word)(x)\n",
    "\n",
    "# Decoder\n",
    "\n",
    "x = get_rnn()(x)\n",
    "x = get_rnn()(x)\n",
    "outp = TimeDistributed(Dense(n_unique_letters, activation='softmax'))(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=outp)\n",
    "model.compile(optimizer='adam', loss= 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at our model in a little more detail.\n",
    "\n",
    "* Our inputs will be phoneme sequences of maximum length 16. These are then fed into an embedding layer which converts each of the 70 phonemes into 120 higher dimensional vectors.\n",
    "\n",
    "\n",
    "* Now, we have a sequences of phoneme embeddings. We need our model to makes some sense of these embedding sequences and convert them into a single distributed representation. This is where RNNs come in. Using RNNs in this scenario makes sense because RNNs can keep state and store memory. This is particularly helpful in our case where the phonemes looked at before might influence the letter which might be generated by the present phoneme.\n",
    "    \n",
    "    \n",
    "    * Why do we have Bidectional? \n",
    "    \n",
    "    * Bidirectional will feed the sequence to an RNN, feed the reverse sequence to another RNN and then concat their results. We do this because in language things that happen later often influence what came before (i.e. in French, \"le garcon, la fille\" means the boy, the girl; the word for \"the\" is determined by the gender of the subject, which comes after).\n",
    "    \n",
    "* This part of taking the input sequence and then converting it into a vector representation, which captures the inherent characteristics which we need to spell, is called the **ENCODER**.\n",
    "\n",
    "\n",
    "* The output of the encoder is then fed into a RepeatVector which does nothing but repeat the encoder's output 15 number of times. This is because at each stage, we want the RNN to keep into account the complete word (letters) that it is trying to spell.\n",
    "\n",
    "\n",
    "* The **DECODER** here is nothing but a bunch of RNNs which take the encoded input and then try to find meaningful insights in that in a way so as to find letters corresponding to them. Its output is fed into a Dense layer with 28 nodes, corresponding to the 28 letters followed by a softmax function.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "We have used 'sparse_categorical_entropy' since we have not done one_hot_encoding for our targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77764 samples, validate on 19441 samples\n",
      "Epoch 1/2\n",
      "77764/77764 [==============================] - 114s 1ms/step - loss: 1.5786 - acc: 0.5410 - val_loss: 1.4739 - val_acc: 0.5622\n",
      "Epoch 2/2\n",
      "77764/77764 [==============================] - 107s 1ms/step - loss: 1.3731 - acc: 0.5846 - val_loss: 1.2106 - val_acc: 0.6222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22b01714e0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_train, np.expand_dims(labels_train,-1), validation_split=0.2, batch_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77764 samples, validate on 19441 samples\n",
      "Epoch 1/2\n",
      "77764/77764 [==============================] - 33s 420us/step - loss: 1.1855 - acc: 0.6280 - val_loss: 1.1216 - val_acc: 0.6458\n",
      "Epoch 2/2\n",
      "77764/77764 [==============================] - 33s 418us/step - loss: 1.1007 - acc: 0.6517 - val_loss: 1.0182 - val_acc: 0.6775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22b0153dd8>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_train, np.expand_dims(labels_train,-1), validation_split=0.2, batch_size=1024, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77764 samples, validate on 19441 samples\n",
      "Epoch 1/5\n",
      "77764/77764 [==============================] - 33s 420us/step - loss: 1.0124 - acc: 0.6779 - val_loss: 0.9284 - val_acc: 0.7054\n",
      "Epoch 2/5\n",
      "77764/77764 [==============================] - 33s 418us/step - loss: 0.9290 - acc: 0.7019 - val_loss: 0.8430 - val_acc: 0.7302\n",
      "Epoch 3/5\n",
      "77764/77764 [==============================] - 33s 418us/step - loss: 0.8535 - acc: 0.7234 - val_loss: 0.7719 - val_acc: 0.7512\n",
      "Epoch 4/5\n",
      "77764/77764 [==============================] - 33s 418us/step - loss: 0.7936 - acc: 0.7407 - val_loss: 0.7150 - val_acc: 0.7690\n",
      "Epoch 5/5\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.7419 - acc: 0.7567 - val_loss: 0.6782 - val_acc: 0.7797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22aa605240>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_train, np.expand_dims(labels_train,-1), validation_split=0.2, batch_size=1024, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77764 samples, validate on 19441 samples\n",
      "Epoch 1/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.7030 - acc: 0.7690 - val_loss: 0.6448 - val_acc: 0.7898\n",
      "Epoch 2/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.6680 - acc: 0.7804 - val_loss: 0.6076 - val_acc: 0.7996\n",
      "Epoch 3/15\n",
      "77764/77764 [==============================] - 33s 418us/step - loss: 0.6385 - acc: 0.7893 - val_loss: 0.6079 - val_acc: 0.8003\n",
      "Epoch 4/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.6150 - acc: 0.7965 - val_loss: 0.5596 - val_acc: 0.8162\n",
      "Epoch 5/15\n",
      "77764/77764 [==============================] - 33s 418us/step - loss: 0.5874 - acc: 0.8061 - val_loss: 0.5360 - val_acc: 0.8233\n",
      "Epoch 6/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.5665 - acc: 0.8125 - val_loss: 0.5193 - val_acc: 0.8292\n",
      "Epoch 7/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.5498 - acc: 0.8176 - val_loss: 0.5096 - val_acc: 0.8319\n",
      "Epoch 8/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.5314 - acc: 0.8234 - val_loss: 0.4891 - val_acc: 0.8384\n",
      "Epoch 9/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.5148 - acc: 0.8286 - val_loss: 0.4773 - val_acc: 0.8426\n",
      "Epoch 10/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.5006 - acc: 0.8338 - val_loss: 0.4880 - val_acc: 0.8386\n",
      "Epoch 11/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.4908 - acc: 0.8363 - val_loss: 0.4519 - val_acc: 0.8505\n",
      "Epoch 12/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.4730 - acc: 0.8426 - val_loss: 0.4509 - val_acc: 0.8488\n",
      "Epoch 13/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.4641 - acc: 0.8455 - val_loss: 0.4534 - val_acc: 0.8508\n",
      "Epoch 14/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.4546 - acc: 0.8482 - val_loss: 0.4305 - val_acc: 0.8583\n",
      "Epoch 15/15\n",
      "77764/77764 [==============================] - 33s 419us/step - loss: 0.4430 - acc: 0.8525 - val_loss: 0.4267 - val_acc: 0.8598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22aa619f98>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_train, np.expand_dims(labels_train,-1), validation_split=0.2, batch_size=1024, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above metric is actually calculating how many letters correct, but we want to know how many of the words we spell correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10801, 15, 28), (15, 28))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each position in the word, we have the probability of that being one of 28 different characters. Let us just take the character with the maximum probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10801, 15), (15,))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(predictions, axis=2)\n",
    "predictions.shape, predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we count a prediction as correct only if all the letters in that word match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2477548375150449"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for real, pred in zip(labels_test, predictions):\n",
    "    if(all(real == pred)):\n",
    "        count += 1\n",
    "acc = count/len(labels_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when comparing complete words, the accuracy drops to almost 25%. This is really low. Let us look at a few predictions to see what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(preds):\n",
    "    print(\"PRONUNCIATION\".ljust(40), \"ACTUAL SPELLING\".ljust(17), \n",
    "          \"PREDICTED SPELLING\".ljust(17), \"IS CORRECT\")\n",
    "\n",
    "    for index in range(20):\n",
    "        ps = \"-\".join([phonemes[p] for p in input_test[index]]) \n",
    "        real = [letters[l] for l in labels_test[index]] \n",
    "        predict = [letters[l] for l in preds[index]]\n",
    "        print (ps.split(\"-_\")[0].ljust(40), \"\".join(real).split(\"_\")[0].ljust(17),\n",
    "            \"\".join(predict).split(\"_\")[0].ljust(17), str(real == predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRONUNCIATION                            ACTUAL SPELLING   PREDICTED SPELLING IS CORRECT\n",
      "L-AY1-T-IY0                              lighty            litty             False\n",
      "S-W-IH1-SH-ER0                           swisher           swisher           True\n",
      "S-AE1-L-IY0                              sallee            sally             False\n",
      "AH0-N-K-W-EH1-S-CH-AH0-N-AH0-B-AH0-L     unquestionable    uncuessiinbble    False\n",
      "M-IH2-D-W-EH1-S-T                        midwest           midwest           True\n",
      "K-AA1-N-T-R-AH0-T-EH2-M-P-S              contretemps       contretomps       False\n",
      "R-IH0-S-EH1-P-SH-AH0-N-IH0-S-T-S         receptionists     recoptiinnits     False\n",
      "M-AA1-N-AE2-SH                           monash            monash            True\n",
      "S-UW2-N-Y-IY1                            soonyi            sunii             False\n",
      "AE1-M-P-L-AH0-F-AY2-ER0-Z                amplifiers        amplifires        False\n",
      "L-IH1-K-IH0-NG                           licking           licking           True\n",
      "AO1-G-ER0-IH0-NG                         auguring          aggrring          False\n",
      "TH-AO1-NG                                thong             thong             True\n",
      "ER0-EY1-N-AH0                            urena             arana             False\n",
      "R-IH0-HH-ER1-S-IH0-NG                    rehearsing        rehersing         False\n",
      "CH-EY1-S-ER0-Z                           chasers           chasers           True\n",
      "K-AA2-R-S-AH0-N-OW0-JH-EH1-N-IH0-K       carcinogenic      carsonogeicc      False\n",
      "D-AH1-S-K-IH0-N                          duskin            duskin            True\n",
      "K-AA0-N-AA1-T-AH0                        cannata           canata            False\n",
      "B-EY1-L-IY0                              baily             bally             False\n"
     ]
    }
   ],
   "source": [
    "print_examples(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the words the model is almost able to get correctly. Like 'sallee' vs 'sally' is an understandable mistake. However, the model performs horribly on words such as 'carcinogenic' and 'carsonogeicc'. \n",
    "\n",
    "The model is performing horribly on words which have a larger length. \n",
    "\n",
    "This can be fixed through attention modeling which we will look at in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
