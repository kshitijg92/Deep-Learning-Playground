{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Handwritten Digit Recognizer using Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of models tried in this notebook : \n",
    "\n",
    "The purpose of this notebook was not to get state of the art results but rather to try our a bunch of different models and ideas.\n",
    "\n",
    "        - Simple Linear Model\n",
    "        - Single Dense Layer Model\n",
    "        - Single Dense Layer Model with Dropout\n",
    "        - Very Basic CNN Model\n",
    "        - CNN with Data Augmentation \n",
    "        - CNN with Data Augmentation and Batch Normalization\n",
    "        - CNN with Data Augmentation, Batch Normalization and Dropouts\n",
    "        - Ensemble (really cool!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D, BatchNormalization, Lambda\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use numpy's loadtxt method in order to load the train data. Setting skiprows to 1 allows us to skip the initial header row.\n",
    "\n",
    "Reference : https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.loadtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data = np.loadtxt('data/digits/train.csv', skiprows=1, dtype='int', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have 42000 training examples with 785 columns. In this case, the first column is the actual label and the rest 784 columns are the flatenned 28x28 image pixel values.\n",
    "\n",
    "Let us look at the first five rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us look at the first few labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3, 1, 2, 0, 7, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0:20,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we want to seperate out our targets, we remove the first column and store it in our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = raw_data[:,1:]\n",
    "Y_train = raw_data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use the convinient train_test_split function of sklearn which will help us split the train data in such a way that 20% of that will go for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784) (33600,) (8400, 784) (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, we need to transform our data back into the 28x28 shape to feed into a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val = X_val.reshape(X_val.shape[0], 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28) (33600,) (8400, 28, 28) (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Let us look at a few of the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAACiCAYAAABBE3gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f033ff6e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,6):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, we need to order the data into the channel ordering which is expected by tenserflow, since we are using Keras with a tensorflow backend\n",
    "\n",
    "Tensorflow follows a CHANNEL_LAST format. (Note channel refers to the color channel, here, it is 1 since we have a grayscale image, it will be 3 for an RGB image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28, 1) (33600,) (8400, 28, 28, 1) (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The labels that we have are int he integer format. We would need to convert them to a categorical format, also called one-hot-encoding, since the loss function that we will be using is 'categorical_crossentropy'\n",
    "\n",
    "Reference : https://keras.io/utils/#to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes=10)\n",
    "Y_val = to_categorical(Y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A Very Simple Linear Model\n",
    "\n",
    "Let us first try to fit a very simple linear model to the data which just has a single Dense softmax layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "NOTE : We are using the BatchNormalization layer as the first layer since we want to normalize the image data before feeding it into the network\n",
    "\n",
    "Reference : https://keras.io/layers/normalization/#batchnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def linear_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(28,28,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,962\n",
      "Trainable params: 7,906\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "linear_model = linear_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the data is too big to fit into memory directly, we use a Keras utility called ImageDataGenerator which generates batches of tensor image data with (optional) real-time data augmentation. The data will be looped over (in batches) indefinitely.\n",
    "\n",
    "Reference : https://keras.io/preprocessing/image/#imagedatagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "gen = image.ImageDataGenerator()\n",
    "train_batches = gen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "valid_batches = gen.flow(X_val, Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the data is generated batch by batch by a generator, we use another Keras utility called fit_generator which fits the model on data generated batch-by-batch by a Python generator.\n",
    "\n",
    "The generator is run in parallel to the model, for efficiency. For instance, this allows you to do (optional) real-time data augmentation on images on CPU in parallel to training your model on GPU.\n",
    "\n",
    "Reference : https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 3s 24ms/step - loss: 0.8172 - acc: 0.7501 - val_loss: 0.4244 - val_acc: 0.8715\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.3782 - acc: 0.8908 - val_loss: 0.3430 - val_acc: 0.8975\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.3277 - acc: 0.9037 - val_loss: 0.3149 - val_acc: 0.9068\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.3031 - acc: 0.9130 - val_loss: 0.3005 - val_acc: 0.9114\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2877 - acc: 0.9173 - val_loss: 0.2987 - val_acc: 0.9143\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2776 - acc: 0.9195 - val_loss: 0.2882 - val_acc: 0.9156\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2696 - acc: 0.9220 - val_loss: 0.2868 - val_acc: 0.9173\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2646 - acc: 0.9242 - val_loss: 0.2861 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2587 - acc: 0.9259 - val_loss: 0.2831 - val_acc: 0.9177\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2566 - acc: 0.9259 - val_loss: 0.2865 - val_acc: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03401f2fd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = int(np.ceil(train_batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(valid_batches.n/batch_size))\n",
    "linear_model.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can see, in just 10 epochs, we are getting validation accuracies of around 91%, which is not bad considering how overtly simple our model iss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single dense layer model\n",
    "\n",
    "Now let us create a model which has a single dense layer in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dense_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(28,28,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 814,202\n",
      "Trainable params: 814,146\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model = dense_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.2881 - acc: 0.9135 - val_loss: 0.1504 - val_acc: 0.9567\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.1011 - acc: 0.9706 - val_loss: 0.1210 - val_acc: 0.9643\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0593 - acc: 0.9822 - val_loss: 0.1027 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0380 - acc: 0.9892 - val_loss: 0.0986 - val_acc: 0.9720\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0225 - acc: 0.9943 - val_loss: 0.1023 - val_acc: 0.9714\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0144 - acc: 0.9966 - val_loss: 0.0964 - val_acc: 0.9740\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0932 - val_acc: 0.9757\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0970 - val_acc: 0.9774\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0872 - val_acc: 0.9788\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f033f8e17f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above model has a clear case of overfitting since our training accuracy has reached 100% but we only have 97.8% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single dense layer model with dropout\n",
    "\n",
    "Since our above model was overfitting, we can add Dropout to it in order to add regularization to our deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dense_model_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(28,28,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_7 (Batch (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 814,202\n",
      "Trainable params: 814,146\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model_drpout = dense_model_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.4106 - acc: 0.8750 - val_loss: 0.1695 - val_acc: 0.9493\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.1845 - acc: 0.9439 - val_loss: 0.1305 - val_acc: 0.9611\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1333 - acc: 0.9590 - val_loss: 0.1091 - val_acc: 0.9664\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.1049 - acc: 0.9670 - val_loss: 0.1032 - val_acc: 0.9695\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0879 - acc: 0.9721 - val_loss: 0.0997 - val_acc: 0.9695\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0779 - acc: 0.9755 - val_loss: 0.0897 - val_acc: 0.9739\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0681 - acc: 0.9780 - val_loss: 0.0910 - val_acc: 0.9732\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0585 - acc: 0.9806 - val_loss: 0.0867 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0547 - acc: 0.9821 - val_loss: 0.0842 - val_acc: 0.9763\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0513 - acc: 0.9830 - val_loss: 0.0860 - val_acc: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f033efb0c50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model_drpout.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can seem the validation accuracy is now increasing along with the train accuracy. Thus dropout has helped reduce overfitting in out network. \n",
    "\n",
    "Running for a few more epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0485 - acc: 0.9839 - val_loss: 0.0901 - val_acc: 0.9767\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0419 - acc: 0.9858 - val_loss: 0.0895 - val_acc: 0.9777\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0393 - acc: 0.9859 - val_loss: 0.0853 - val_acc: 0.9796\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0379 - acc: 0.9874 - val_loss: 0.0896 - val_acc: 0.9773\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0356 - acc: 0.9878 - val_loss: 0.0899 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0321 - acc: 0.9895 - val_loss: 0.0954 - val_acc: 0.9768\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0343 - acc: 0.9886 - val_loss: 0.0894 - val_acc: 0.9782\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0319 - acc: 0.9889 - val_loss: 0.0921 - val_acc: 0.9773\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0305 - acc: 0.9897 - val_loss: 0.0912 - val_acc: 0.9793\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.0335 - acc: 0.9885 - val_loss: 0.0879 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f033f01a400>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model_drpout.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Very basic CNN model\n",
    "\n",
    "The previous model with a single dense layer gave us Validation accuracies of almost 98%. Let us now try to fit a very simply CNN model to the data. \n",
    "\n",
    "This CNN architecture is heavily inspired by the VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def basic_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(28,28,1)))\n",
    "    \n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, (3,3) ,activation='relu'))\n",
    "    model.add(Convolution2D(128, (3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,887,226\n",
      "Trainable params: 2,887,170\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "basic_cnn_model = basic_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.4877 - acc: 0.8373 - val_loss: 0.1802 - val_acc: 0.9475\n",
      "Epoch 2/5\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1264 - acc: 0.9610 - val_loss: 0.1199 - val_acc: 0.9620\n",
      "Epoch 3/5\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0919 - acc: 0.9716 - val_loss: 0.0759 - val_acc: 0.9756\n",
      "Epoch 4/5\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0721 - acc: 0.9779 - val_loss: 0.0684 - val_acc: 0.9806\n",
      "Epoch 5/5\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0594 - acc: 0.9816 - val_loss: 0.0767 - val_acc: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f033c976550>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cnn_model.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 5, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets decrease the learning rate and run for a few more epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0551 - acc: 0.9821 - val_loss: 0.0540 - val_acc: 0.9844\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0557 - acc: 0.9823 - val_loss: 0.0550 - val_acc: 0.9843\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0519 - acc: 0.9848 - val_loss: 0.0601 - val_acc: 0.9832\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0444 - acc: 0.9859 - val_loss: 0.0529 - val_acc: 0.9838\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0429 - acc: 0.9869 - val_loss: 0.0507 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0399 - acc: 0.9876 - val_loss: 0.0560 - val_acc: 0.9838\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0394 - acc: 0.9876 - val_loss: 0.0486 - val_acc: 0.9858\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0367 - acc: 0.9888 - val_loss: 0.0536 - val_acc: 0.9858\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0378 - acc: 0.9882 - val_loss: 0.0510 - val_acc: 0.9860\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0357 - acc: 0.9892 - val_loss: 0.0511 - val_acc: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03376309b0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cnn_model.optimizer.lr = 0.001\n",
    "basic_cnn_model.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A few more epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0353 - acc: 0.9893 - val_loss: 0.0432 - val_acc: 0.9885\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0374 - acc: 0.9886 - val_loss: 0.0461 - val_acc: 0.9865\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0346 - acc: 0.9886 - val_loss: 0.0397 - val_acc: 0.9880\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.0574 - val_acc: 0.9839\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.0517 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.0327 - acc: 0.9902 - val_loss: 0.0490 - val_acc: 0.9861\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0286 - acc: 0.9910 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0303 - acc: 0.9905 - val_loss: 0.0442 - val_acc: 0.9869\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0277 - acc: 0.9916 - val_loss: 0.0458 - val_acc: 0.9871\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0272 - acc: 0.9917 - val_loss: 0.0427 - val_acc: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03401460f0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cnn_model.optimizer.lr = 0.001\n",
    "basic_cnn_model.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Data Augmentation\n",
    "\n",
    "One cool trick to combat overfitting is to generate artificial data in order to increase the amount of data we have. This can be done easily in Keras with the help of the ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(zoom_range=0.15, height_shift_range=0.15, width_shift_range=0.15, rotation_range=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,887,226\n",
      "Trainable params: 2,887,170\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_batches = gen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "valid_batches = gen.flow(X_val, Y_val, batch_size=batch_size)\n",
    "basic_cnn_aug = basic_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 13s 95ms/step - loss: 1.8973 - acc: 0.3383 - val_loss: 0.6119 - val_acc: 0.7968\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.4237 - acc: 0.8617 - val_loss: 0.3591 - val_acc: 0.8870\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.2851 - acc: 0.9100 - val_loss: 0.2842 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.2410 - acc: 0.9237 - val_loss: 0.2426 - val_acc: 0.9223\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.2146 - acc: 0.9328 - val_loss: 0.1972 - val_acc: 0.9376\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.1970 - acc: 0.9393 - val_loss: 0.1960 - val_acc: 0.9420\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.1826 - acc: 0.9439 - val_loss: 0.2032 - val_acc: 0.9377\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.1797 - acc: 0.9453 - val_loss: 0.1835 - val_acc: 0.9473\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1779 - acc: 0.9436 - val_loss: 0.1609 - val_acc: 0.9520\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1649 - acc: 0.9490 - val_loss: 0.1568 - val_acc: 0.9513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03373afa90>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cnn_aug.optimizer.lr = 0.01\n",
    "basic_cnn_aug.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running for a few more epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.1682 - acc: 0.9482 - val_loss: 0.1580 - val_acc: 0.9519\n",
      "Epoch 2/12\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1580 - acc: 0.9520 - val_loss: 0.1501 - val_acc: 0.9551\n",
      "Epoch 3/12\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.1557 - acc: 0.9531 - val_loss: 0.1460 - val_acc: 0.9560\n",
      "Epoch 4/12\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1462 - acc: 0.9550 - val_loss: 0.1910 - val_acc: 0.9419\n",
      "Epoch 5/12\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1491 - acc: 0.9551 - val_loss: 0.1551 - val_acc: 0.9562\n",
      "Epoch 6/12\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.1508 - acc: 0.9542 - val_loss: 0.1577 - val_acc: 0.9554\n",
      "Epoch 7/12\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.1490 - acc: 0.9545 - val_loss: 0.1759 - val_acc: 0.9475\n",
      "Epoch 8/12\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.1373 - acc: 0.9564 - val_loss: 0.1470 - val_acc: 0.9604\n",
      "Epoch 9/12\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1387 - acc: 0.9574 - val_loss: 0.1342 - val_acc: 0.9587\n",
      "Epoch 10/12\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1372 - acc: 0.9577 - val_loss: 0.1602 - val_acc: 0.9510\n",
      "Epoch 11/12\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.1413 - acc: 0.9574 - val_loss: 0.1337 - val_acc: 0.9583\n",
      "Epoch 12/12\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.1451 - acc: 0.9555 - val_loss: 0.1519 - val_acc: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f032759c8d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cnn_aug.optimizer.lr = 0.01\n",
    "basic_cnn_aug.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 12, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.1240 - acc: 0.9627 - val_loss: 0.1346 - val_acc: 0.9611\n",
      "Epoch 2/12\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1304 - acc: 0.9606 - val_loss: 0.1983 - val_acc: 0.9399\n",
      "Epoch 3/12\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.1401 - acc: 0.9592 - val_loss: 0.1445 - val_acc: 0.9582\n",
      "Epoch 4/12\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.1345 - acc: 0.9598 - val_loss: 0.1500 - val_acc: 0.9576\n",
      "Epoch 5/12\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1239 - acc: 0.9624 - val_loss: 0.1352 - val_acc: 0.9586\n",
      "Epoch 6/12\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 0.1328 - acc: 0.9607 - val_loss: 0.1656 - val_acc: 0.9557\n",
      "Epoch 7/12\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 0.1327 - acc: 0.9610 - val_loss: 0.1420 - val_acc: 0.9585\n",
      "Epoch 8/12\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 0.1335 - acc: 0.9595 - val_loss: 0.1329 - val_acc: 0.9596\n",
      "Epoch 9/12\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 0.1390 - acc: 0.9586 - val_loss: 0.1414 - val_acc: 0.9573\n",
      "Epoch 10/12\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1314 - acc: 0.9617 - val_loss: 0.1379 - val_acc: 0.9613\n",
      "Epoch 11/12\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.1326 - acc: 0.9607 - val_loss: 0.1370 - val_acc: 0.9575\n",
      "Epoch 12/12\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.1302 - acc: 0.9615 - val_loss: 0.1334 - val_acc: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0339664860>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cnn_aug.optimizer.lr = 0.001\n",
    "basic_cnn_aug.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 12, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN with Data Augmentation and Batch Normalization\n",
    "\n",
    "One of the most important tasks in Deep Neural Networks is to perform batch_normalizations across the layers which applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. This prevents some activations from scaling up or down too much and also helps speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cnn_with_augmentaion_bn():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(28,28,1)))\n",
    "    \n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, (3,3) ,activation='relu'))\n",
    "    model.add(Convolution2D(128, (3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_13 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_augmented_bn = cnn_with_augmentaion_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.3481 - acc: 0.8922 - val_loss: 0.8443 - val_acc: 0.7529\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.1141 - acc: 0.9645 - val_loss: 0.3491 - val_acc: 0.8954\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0864 - acc: 0.9736 - val_loss: 0.1189 - val_acc: 0.9618\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0713 - acc: 0.9780 - val_loss: 0.1210 - val_acc: 0.9649\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0600 - acc: 0.9813 - val_loss: 0.1049 - val_acc: 0.9680\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0638 - acc: 0.9799 - val_loss: 0.0851 - val_acc: 0.9740\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0527 - acc: 0.9836 - val_loss: 0.0777 - val_acc: 0.9760\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0531 - acc: 0.9826 - val_loss: 0.0792 - val_acc: 0.9775\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0461 - acc: 0.9853 - val_loss: 0.0815 - val_acc: 0.9770\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0455 - acc: 0.9856 - val_loss: 0.0631 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0338633f28>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_augmented_bn.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can seem the model with batch normalization is taking fewer epochs to reach higher accuracies than the one without batch normalization.\n",
    "\n",
    "Lets run this model for a few more epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0344 - acc: 0.9887 - val_loss: 0.0505 - val_acc: 0.9864\n",
      "Epoch 2/5\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0362 - acc: 0.9879 - val_loss: 0.0574 - val_acc: 0.9851\n",
      "Epoch 3/5\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0343 - acc: 0.9892 - val_loss: 0.0578 - val_acc: 0.9844\n",
      "Epoch 4/5\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0335 - acc: 0.9891 - val_loss: 0.0470 - val_acc: 0.9873\n",
      "Epoch 5/5\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0321 - acc: 0.9893 - val_loss: 0.0532 - val_acc: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0337669940>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_augmented_bn.optimizer.lr = 0.001\n",
    "cnn_augmented_bn.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 5, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN With Data Augmentation, Batch Normalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cnn_with_augmentaion_bn_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(28,28,1)))\n",
    "    \n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, (3,3) ,activation='relu'))\n",
    "    model.add(Convolution2D(128, (3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_16 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model_cnn = cnn_with_augmentaion_bn_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.4660 - acc: 0.8529 - val_loss: 0.6893 - val_acc: 0.8786\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.1305 - acc: 0.9603 - val_loss: 0.1908 - val_acc: 0.9569\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0998 - acc: 0.9697 - val_loss: 0.1552 - val_acc: 0.9510\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0813 - acc: 0.9753 - val_loss: 0.0864 - val_acc: 0.9730\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0740 - acc: 0.9777 - val_loss: 0.0932 - val_acc: 0.9702\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0622 - acc: 0.9807 - val_loss: 0.0810 - val_acc: 0.9775\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0564 - acc: 0.9829 - val_loss: 0.0647 - val_acc: 0.9799\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0545 - acc: 0.9825 - val_loss: 0.0780 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0527 - acc: 0.9838 - val_loss: 0.0584 - val_acc: 0.9830\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0499 - acc: 0.9846 - val_loss: 0.0613 - val_acc: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f032746e9b0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_cnn.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Running for a few more epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0441 - acc: 0.9859 - val_loss: 0.0469 - val_acc: 0.9863\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0436 - acc: 0.9863 - val_loss: 0.0567 - val_acc: 0.9838\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0389 - acc: 0.9876 - val_loss: 0.0474 - val_acc: 0.9854\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0419 - acc: 0.9872 - val_loss: 0.0523 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0437 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0372 - acc: 0.9879 - val_loss: 0.0479 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0356 - acc: 0.9893 - val_loss: 0.0471 - val_acc: 0.9861\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0364 - acc: 0.9881 - val_loss: 0.0385 - val_acc: 0.9879\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0334 - acc: 0.9895 - val_loss: 0.0455 - val_acc: 0.9876\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0337 - acc: 0.9889 - val_loss: 0.0491 - val_acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0323da8e80>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_cnn.optimizer.lr = 0.001\n",
    "full_model_cnn.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ensemble \n",
    "\n",
    "One of the coolest and most handy tricks in machine learning is to create an ensemble of models and then average over their predictions. This gives us a boost to our accuracies of about 0.5%\n",
    "\n",
    "Let us get an ensemble over the full CNN model that we had just before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble():\n",
    "    full_model_cnn = cnn_with_augmentaion_bn_dropout()\n",
    "    full_model_cnn.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)\n",
    "    full_model_cnn.optimizer.lr = 0.001\n",
    "    full_model_cnn.fit_generator(train_batches, steps_per_epoch=steps_per_epoch, \\\n",
    "                                               epochs = 10, validation_data = valid_batches, \\\n",
    "                                               validation_steps= validation_steps)\n",
    "    return full_model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_19 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.4536 - acc: 0.8564 - val_loss: 1.0322 - val_acc: 0.6154\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.1254 - acc: 0.9608 - val_loss: 0.1966 - val_acc: 0.9533\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1002 - acc: 0.9687 - val_loss: 0.2010 - val_acc: 0.9343\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.0846 - acc: 0.9732 - val_loss: 0.0862 - val_acc: 0.9757\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0661 - acc: 0.9795 - val_loss: 0.0706 - val_acc: 0.9799\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0658 - acc: 0.9792 - val_loss: 0.0901 - val_acc: 0.9752\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0581 - acc: 0.9809 - val_loss: 0.0757 - val_acc: 0.9786\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0536 - acc: 0.9832 - val_loss: 0.0627 - val_acc: 0.9839\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0505 - acc: 0.9843 - val_loss: 0.0758 - val_acc: 0.9773\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0478 - acc: 0.9854 - val_loss: 0.0619 - val_acc: 0.9830\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.0442 - acc: 0.9860 - val_loss: 0.0546 - val_acc: 0.9833\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0423 - acc: 0.9862 - val_loss: 0.0549 - val_acc: 0.9846\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.0394 - acc: 0.9880 - val_loss: 0.0541 - val_acc: 0.9849\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0406 - acc: 0.9864 - val_loss: 0.0520 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0403 - acc: 0.9872 - val_loss: 0.0713 - val_acc: 0.9807\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0356 - acc: 0.9881 - val_loss: 0.0556 - val_acc: 0.9849\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0357 - acc: 0.9890 - val_loss: 0.0702 - val_acc: 0.9801\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0344 - acc: 0.9890 - val_loss: 0.0442 - val_acc: 0.9875\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0401 - acc: 0.9879 - val_loss: 0.0494 - val_acc: 0.9868\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0332 - acc: 0.9898 - val_loss: 0.0505 - val_acc: 0.9856\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_22 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.4720 - acc: 0.8514 - val_loss: 0.6295 - val_acc: 0.8992\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1299 - acc: 0.9602 - val_loss: 0.2362 - val_acc: 0.9351\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0980 - acc: 0.9698 - val_loss: 0.1436 - val_acc: 0.9573\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0806 - acc: 0.9758 - val_loss: 0.1096 - val_acc: 0.9681\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0733 - acc: 0.9770 - val_loss: 0.0868 - val_acc: 0.9733\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0616 - acc: 0.9811 - val_loss: 0.0689 - val_acc: 0.9815\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0563 - acc: 0.9822 - val_loss: 0.0705 - val_acc: 0.9806\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0523 - acc: 0.9830 - val_loss: 0.0564 - val_acc: 0.9837\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0476 - acc: 0.9848 - val_loss: 0.0604 - val_acc: 0.9818\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0485 - acc: 0.9844 - val_loss: 0.0700 - val_acc: 0.9801\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0457 - acc: 0.9863 - val_loss: 0.0583 - val_acc: 0.9850\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0444 - acc: 0.9853 - val_loss: 0.0703 - val_acc: 0.9787\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.0515 - val_acc: 0.9861\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0402 - acc: 0.9874 - val_loss: 0.0663 - val_acc: 0.9831\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0401 - acc: 0.9880 - val_loss: 0.0452 - val_acc: 0.9863\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0398 - acc: 0.9878 - val_loss: 0.0530 - val_acc: 0.9837\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0395 - acc: 0.9877 - val_loss: 0.0538 - val_acc: 0.9855\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0348 - acc: 0.9890 - val_loss: 0.0475 - val_acc: 0.9864\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0357 - acc: 0.9888 - val_loss: 0.0581 - val_acc: 0.9832\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0355 - acc: 0.9892 - val_loss: 0.0451 - val_acc: 0.9863\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_25 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 94ms/step - loss: 0.4494 - acc: 0.8581 - val_loss: 0.6618 - val_acc: 0.8827\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1281 - acc: 0.9601 - val_loss: 0.2082 - val_acc: 0.9533\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0967 - acc: 0.9706 - val_loss: 0.0856 - val_acc: 0.9731\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0750 - acc: 0.9764 - val_loss: 0.0889 - val_acc: 0.9725\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0689 - acc: 0.9785 - val_loss: 0.0848 - val_acc: 0.9770\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0644 - acc: 0.9798 - val_loss: 0.0680 - val_acc: 0.9800\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0616 - acc: 0.9804 - val_loss: 0.0816 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0533 - acc: 0.9836 - val_loss: 0.0548 - val_acc: 0.9840\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0540 - acc: 0.9824 - val_loss: 0.0447 - val_acc: 0.9862\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0491 - acc: 0.9858 - val_loss: 0.0588 - val_acc: 0.9825\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0454 - acc: 0.9860 - val_loss: 0.0548 - val_acc: 0.9854\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0424 - acc: 0.9868 - val_loss: 0.0455 - val_acc: 0.9848\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0395 - acc: 0.9878 - val_loss: 0.0540 - val_acc: 0.9846\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.0402 - acc: 0.9873 - val_loss: 0.0636 - val_acc: 0.9794\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0412 - acc: 0.9870 - val_loss: 0.0690 - val_acc: 0.9817\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0397 - acc: 0.9881 - val_loss: 0.0592 - val_acc: 0.9823\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0365 - acc: 0.9887 - val_loss: 0.0524 - val_acc: 0.9863\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0360 - acc: 0.9884 - val_loss: 0.0511 - val_acc: 0.9851\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0341 - acc: 0.9893 - val_loss: 0.0472 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0386 - acc: 0.9884 - val_loss: 0.0543 - val_acc: 0.9848\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_28 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 13s 95ms/step - loss: 0.4648 - acc: 0.8540 - val_loss: 0.5767 - val_acc: 0.9105\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1360 - acc: 0.9581 - val_loss: 0.1713 - val_acc: 0.9580\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0952 - acc: 0.9706 - val_loss: 0.0785 - val_acc: 0.9755\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0776 - acc: 0.9762 - val_loss: 0.0922 - val_acc: 0.9726\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0725 - acc: 0.9775 - val_loss: 0.0813 - val_acc: 0.9751\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0680 - acc: 0.9789 - val_loss: 0.0947 - val_acc: 0.9714\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0591 - acc: 0.9811 - val_loss: 0.0766 - val_acc: 0.9785\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0572 - acc: 0.9822 - val_loss: 0.0689 - val_acc: 0.9796\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0594 - acc: 0.9821 - val_loss: 0.0546 - val_acc: 0.9837\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0473 - acc: 0.9856 - val_loss: 0.0481 - val_acc: 0.9851\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 0.0447 - acc: 0.9859 - val_loss: 0.0819 - val_acc: 0.9754\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0429 - acc: 0.9870 - val_loss: 0.0534 - val_acc: 0.9845\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0431 - acc: 0.9862 - val_loss: 0.0545 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0413 - acc: 0.9870 - val_loss: 0.0594 - val_acc: 0.9843\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0378 - acc: 0.9883 - val_loss: 0.0475 - val_acc: 0.9870\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0538 - val_acc: 0.9844\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.0469 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0384 - acc: 0.9883 - val_loss: 0.0515 - val_acc: 0.9839\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0366 - acc: 0.9881 - val_loss: 0.0570 - val_acc: 0.9833\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0328 - acc: 0.9895 - val_loss: 0.0494 - val_acc: 0.9860\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_31 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 13s 97ms/step - loss: 0.4718 - acc: 0.8514 - val_loss: 0.6290 - val_acc: 0.9090\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1285 - acc: 0.9604 - val_loss: 0.2027 - val_acc: 0.9439\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0974 - acc: 0.9694 - val_loss: 0.1098 - val_acc: 0.9648\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0838 - acc: 0.9736 - val_loss: 0.0698 - val_acc: 0.9770\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0724 - acc: 0.9781 - val_loss: 0.0849 - val_acc: 0.9755\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0627 - acc: 0.9804 - val_loss: 0.0891 - val_acc: 0.9760\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0599 - acc: 0.9816 - val_loss: 0.0699 - val_acc: 0.9790\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0524 - acc: 0.9837 - val_loss: 0.0625 - val_acc: 0.9821\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0502 - acc: 0.9840 - val_loss: 0.0538 - val_acc: 0.9845\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0475 - acc: 0.9846 - val_loss: 0.0632 - val_acc: 0.9825\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.0448 - acc: 0.9856 - val_loss: 0.0530 - val_acc: 0.9843\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0438 - acc: 0.9866 - val_loss: 0.0488 - val_acc: 0.9856\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0393 - acc: 0.9870 - val_loss: 0.0539 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0412 - acc: 0.9870 - val_loss: 0.0509 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0394 - acc: 0.9879 - val_loss: 0.0529 - val_acc: 0.9846\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0373 - acc: 0.9879 - val_loss: 0.0484 - val_acc: 0.9862\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0385 - acc: 0.9874 - val_loss: 0.0444 - val_acc: 0.9877\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0346 - acc: 0.9889 - val_loss: 0.0511 - val_acc: 0.9865\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0355 - acc: 0.9888 - val_loss: 0.0489 - val_acc: 0.9862\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0344 - acc: 0.9896 - val_loss: 0.0475 - val_acc: 0.9885\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_34 (Batc (None, 28, 28, 1)         112       \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,893,370\n",
      "Trainable params: 2,890,242\n",
      "Non-trainable params: 3,128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 13s 97ms/step - loss: 0.4382 - acc: 0.8626 - val_loss: 0.6135 - val_acc: 0.8963\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.1297 - acc: 0.9594 - val_loss: 0.2202 - val_acc: 0.9383\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.1018 - acc: 0.9677 - val_loss: 0.0855 - val_acc: 0.9751\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0801 - acc: 0.9749 - val_loss: 0.0827 - val_acc: 0.9740\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0662 - acc: 0.9791 - val_loss: 0.0668 - val_acc: 0.9798\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0636 - acc: 0.9803 - val_loss: 0.0692 - val_acc: 0.9795\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0599 - acc: 0.9813 - val_loss: 0.0828 - val_acc: 0.9760\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0529 - acc: 0.9838 - val_loss: 0.0581 - val_acc: 0.9839\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0498 - acc: 0.9847 - val_loss: 0.0743 - val_acc: 0.9793\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0483 - acc: 0.9850 - val_loss: 0.0550 - val_acc: 0.9849\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.0449 - acc: 0.9855 - val_loss: 0.0562 - val_acc: 0.9833\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 85ms/step - loss: 0.0458 - acc: 0.9861 - val_loss: 0.0626 - val_acc: 0.9815\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 84ms/step - loss: 0.0463 - acc: 0.9862 - val_loss: 0.0523 - val_acc: 0.9835\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0419 - acc: 0.9870 - val_loss: 0.0468 - val_acc: 0.9865\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 0.0361 - acc: 0.9887 - val_loss: 0.0777 - val_acc: 0.9799\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.0360 - acc: 0.9881 - val_loss: 0.0454 - val_acc: 0.9875\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0485 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.0371 - acc: 0.9884 - val_loss: 0.0463 - val_acc: 0.9881\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 0.0359 - acc: 0.9892 - val_loss: 0.0452 - val_acc: 0.9874\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.0478 - val_acc: 0.9871\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = [get_ensemble() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, model in enumerate(ensemble_model):\n",
    "    model.save_weights('data/digits/models/' + 'digits_'+str(i)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = np.loadtxt('data/digits/test.csv', skiprows=1, dtype='int', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us now see how the ensemble model does on our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds_val = np.stack([m.predict(X_val, batch_size=256) for m in ensemble_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8400, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets get the mean over all the models in the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_preds_val = all_preds_val.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 10)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.06542074e-06,   9.99973476e-01,   3.05996906e-07,\n",
       "          3.16588853e-07,   1.05535355e-06,   1.42864096e-07,\n",
       "          1.83400589e-05,   2.28498425e-06,   6.96512700e-07,\n",
       "          3.88996028e-07],\n",
       "       [  4.61973180e-08,   9.99992430e-01,   3.64074495e-08,\n",
       "          5.03943376e-09,   1.07002130e-07,   4.16276755e-08,\n",
       "          2.29539111e-07,   6.73313843e-06,   3.16081450e-09,\n",
       "          3.96366460e-07],\n",
       "       [  2.18388454e-08,   1.77901242e-07,   1.40553496e-07,\n",
       "          1.53146840e-09,   9.99996185e-01,   8.03152318e-08,\n",
       "          1.67182634e-07,   2.37736208e-06,   1.02998833e-07,\n",
       "          8.19700801e-07],\n",
       "       [  2.00937808e-04,   9.95867014e-01,   1.37414376e-04,\n",
       "          1.11548343e-06,   1.56365437e-04,   3.20941072e-05,\n",
       "          3.24417162e-03,   1.97875910e-04,   1.49906962e-04,\n",
       "          1.31269335e-05],\n",
       "       [  2.10252051e-06,   4.04362517e-08,   3.07205710e-07,\n",
       "          3.06940569e-06,   7.30098151e-08,   2.05543915e-06,\n",
       "          2.23721672e-05,   7.45355722e-10,   9.99969900e-01,\n",
       "          8.42293488e-08]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds_val[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our current predictions holds the probabilities of each label in the target. Lets predict the label to be the one with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_preds_val = np.argmax(avg_preds_val, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99464285714285716"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(avg_preds_val, np.argmax(Y_val, axis =1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our accuracy of each model individually on the validation set was around 98.8%. On putting an ensemble of just 6 of those models, our accuracies shot up to around 99.5%.\n",
    "\n",
    "NOTE : After submitting the predictions of this ensemble on the test set on Kaggle, our score was 99.67%\n",
    "\n",
    "Let us now create out submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in ensemble_model])\n",
    "avg_pred = all_preds.mean(axis=0)\n",
    "avg_preds_label = np.argmax(avg_pred, axis = 1)\n",
    "avg_preds_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ids = np.arange(1,28001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 27998, 27999, 28000])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission = np.stack([ids, avg_preds_label], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     2],\n",
       "       [    2,     0],\n",
       "       [    3,     9],\n",
       "       ..., \n",
       "       [27998,     3],\n",
       "       [27999,     9],\n",
       "       [28000,     2]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'data/digits/results/submission.csv'\n",
    "np.savetxt(submission_file_name, submission, fmt='%d,%d', header='ImageId,Label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/digits/results/submission.csv' target='_blank'>data/digits/results/submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/kshitijg1992/fastai/courses/deeplearning1/nbs/data/digits/results/submission.csv"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('data/digits/results/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
