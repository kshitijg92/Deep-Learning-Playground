{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on IMDB\n",
    "\n",
    "This notebook explores various models for sentiment analysis on the IMDB dataset. I have tried the following models : \n",
    "     - Basic Linear Model\n",
    "     - Simple Convolution Model\n",
    "     - Model With Pre-Trained Word Embeddings\n",
    "     - Recurrent Neural Networks \n",
    "         - Simple LSTM Model\n",
    "         - Convolution with LSTM Model\n",
    "         - Simple GRU Model\n",
    "         - Convolution with GRU Model\n",
    "         \n",
    "Reference : This notebook was developed during the Deep Learning Course by Fast.ai and as such is heavily influenced by it (https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "from PIL import Image\n",
    "import gc,re\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, LSTM, GRU, Embedding, Convolution1D, MaxPooling1D, MaxPool1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from importlib import reload\n",
    "from keras import backend as K\n",
    "from keras.datasets import imdb\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "import bcolz\n",
    "from IPython.display import FileLink\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "SEQ_LEN = 500\n",
    "EMBEDDING_LEN_50 = 50\n",
    "EMBEDDING_LEN_100 = 100\n",
    "EMBEDDING_LEN_200 = 200\n",
    "EMBEDDING_LEN_300 = 300\n",
    "\n",
    "PATH = 'data/imdb/'\n",
    "MODELS = PATH + 'models/'\n",
    "GLOVE_DIRECTORY = 'data/wordembeddings/'\n",
    "\n",
    "GLOVE_50_DIM = GLOVE_DIRECTORY + 'glove.6B.50d.txt'\n",
    "GLOVE_100_DIM = GLOVE_DIRECTORY + 'glove.6B.100d.txt'\n",
    "GLOVE_200_DIM = GLOVE_DIRECTORY + 'glove.6B.200d.txt'\n",
    "GLOVE_300_DIM = GLOVE_DIRECTORY + 'glove.6B.300d.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(MODELS):\n",
    "    os.mkdir(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Quick look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One of the good things about working with this particular dataset is that it is already present within the Keras library. As such, we can directly load this dataset and start working with it. \n",
    "\n",
    "Reference : https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "IMDB dataset has a dictionary which stores the index of all the unique words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "88584\n"
     ]
    }
   ],
   "source": [
    "word2index = imdb.get_word_index()\n",
    "print(word2index['and'])\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we see above, there are 88584 unique words in the IMDB dataset.\n",
    "\n",
    "We will use this dictionary to create a reverse mapping from the index to the word which we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word = {v : k for k,v in word2index.items()}\n",
    "index2word[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us now see how one of the reviews looks like.\n",
    "\n",
    "As we can see, each review contains indices of the words it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index2word[i] for i in X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us see the label of this review.\n",
    "\n",
    "1 is for positive and 0 is for a negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, let us look at a negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the thought solid thought senator do making to is spot nomination assumed while he of jack in where picked as getting on was did hands fact characters to always life thrillers not as me can't in at are br of sure your way of little it strongly random to view of love it so principles of guy it used producer of where it of here icon film of outside to don't all unique some like of direction it if out her imagination below keep of queen he diverse to makes this stretch stefan of solid it thought begins br senator machinations budget worthwhile though ok brokedown awaiting for ever better were lugia diverse for budget look kicked any to of making it out bosworth's follows for effects show to show cast this family us scenes more it severe making senator to levant's finds tv tend to of emerged these thing wants but fuher an beckinsale cult as it is video do you david see scenery it in few those are of ship for with of wild to one is very work dark they don't do dvd with those them\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index2word[i] for i in X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we had seen before, we have almost 89k different words in the dataset. The load_data() method of keras imdb dataset gives us the option of only taking the top n words if we so desire.\n",
    "\n",
    "Here, we will load the dataset with top 5000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = imdb.load_data(num_words=VOCAB_SIZE, oov_char=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us now see the max, the mean and the minimum review lengths in the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_train_reviews = [len(i) for i in X_train]\n",
    "len_test_reviews = [len(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494 238.71364 11\n"
     ]
    }
   ],
   "source": [
    "print(max(len_train_reviews), np.mean(len_train_reviews), min(len_train_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2315 230.8042 7\n"
     ]
    }
   ],
   "source": [
    "print(max(len_test_reviews), np.mean(len_test_reviews), min(len_test_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most reviews are around 230-240 words. So, what we can do is truncate each review to a length of 500 (which is almost double average review length). Reviews which are shorter will get padded with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = sequence.pad_sequences(X_train,SEQ_LEN)\n",
    "test = sequence.pad_sequences(X_test,SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,   14,   22,\n",
       "         16,   43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,  173,   36,  256,\n",
       "          5,   25,  100,   43,  838,  112,   50,  670, 5000,    9,   35,  480,  284,    5,  150,\n",
       "          4,  172,  112,  167, 5000,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
       "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,   22,    4, 1920, 4613,\n",
       "        469,    4,   22,   71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,    4,\n",
       "         22,   17,  515,   17,   12,   16,  626,   18, 5000,    5,   62,  386,   12,    8,  316,\n",
       "          8,  106,    5,    4, 2223, 5000,   16,  480,   66, 3785,   33,    4,  130,   12,   16,\n",
       "         38,  619,    5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,    6,   22,   12,\n",
       "        215,   28,   77,   52,    5,   14,  407,   16,   82, 5000,    8,    4,  107,  117, 5000,\n",
       "         15,  256,    4, 5000,    7, 3766,    5,  723,   36,   71,   43,  530,  476,   26,  400,\n",
       "        317,   46,    7,    4, 5000, 1029,   13,  104,   88,    4,  381,   15,  297,   98,   32,\n",
       "       2071,   56,   26,  141,    6,  194, 5000,   18,    4,  226,   22,   21,  134,  476,   26,\n",
       "        480,    5,  144,   30, 5000,   18,   51,   36,   28,  224,   92,   25,  104,    4,  226,\n",
       "         65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
       "         16, 5000,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Converting the targets to categorical targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For text processing we use an embedding layer. This layer represents our words as vectors of some particular length (here EMBEDDING_LEN_50) in some higher dimensional space. We do this to help capture the semantic relationship between the words.\n",
    "\n",
    "References : https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "References : https://keras.io/layers/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               2500100   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 2,750,702\n",
      "Trainable params: 2,750,502\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "x = Dropout(0.2)(emb)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "preds = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "linear_model = Model(inputs=inp, outputs=preds)\n",
    "linear_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 2s 84us/step - loss: 0.7591 - acc: 0.5079 - val_loss: 0.6926 - val_acc: 0.5124\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6357 - acc: 0.6289 - val_loss: 0.6679 - val_acc: 0.5716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b01990b00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.3376 - acc: 0.8606 - val_loss: 0.5289 - val_acc: 0.8594\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.1498 - acc: 0.9487 - val_loss: 0.4466 - val_acc: 0.8682\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0686 - acc: 0.9819 - val_loss: 0.3720 - val_acc: 0.8610\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0353 - acc: 0.9915 - val_loss: 0.3340 - val_acc: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b014ebc50>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We see that the linear model is getting almost 86% validation accuracies. It is highly overfitting. Let us next see what a more complex model is able to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del linear_model\n",
    "for i in range(0,5):\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple Convolution Model\n",
    "\n",
    "Convultions are good at finding spatial relationships. As such, its intuitive they might work for **embedded** text data too since they can find spatial relations among the word vectors in the high dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 64)           12864     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 64)           16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,879,614\n",
      "Trainable params: 1,879,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "conv = Convolution1D(filters=64, kernel_size=4, padding='same', activation='relu')(emb)\n",
    "conv = Convolution1D(filters=64, kernel_size=4, padding='same', activation='relu')(conv)\n",
    "pool = MaxPooling1D(pool_size=2)(conv) \n",
    "x = Dropout(0.4)(pool)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.6)(x)\n",
    "preds = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "conv_model = Model(inputs=inp, outputs=preds)\n",
    "conv_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 5s 263us/step - loss: 0.6923 - acc: 0.5197 - val_loss: 0.6788 - val_acc: 0.6528\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.4795 - acc: 0.7700 - val_loss: 0.2998 - val_acc: 0.8748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b02da2c18>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.optimizer.lr = 1e-3\n",
    "conv_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/6\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.2575 - acc: 0.9030 - val_loss: 0.2911 - val_acc: 0.8802\n",
      "Epoch 2/6\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.1933 - acc: 0.9284 - val_loss: 0.2841 - val_acc: 0.8854\n",
      "Epoch 3/6\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.1587 - acc: 0.9435 - val_loss: 0.3148 - val_acc: 0.8864\n",
      "Epoch 4/6\n",
      "20000/20000 [==============================] - 5s 236us/step - loss: 0.1396 - acc: 0.9504 - val_loss: 0.3244 - val_acc: 0.8856\n",
      "Epoch 5/6\n",
      "20000/20000 [==============================] - 5s 236us/step - loss: 0.1257 - acc: 0.9565 - val_loss: 0.3576 - val_acc: 0.8852\n",
      "Epoch 6/6\n",
      "20000/20000 [==============================] - 5s 237us/step - loss: 0.0899 - acc: 0.9702 - val_loss: 0.4330 - val_acc: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b030bb358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.optimizer.lr = 1e-5\n",
    "conv_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we see, this simple convolutional model is performing quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have seen before for images that we can just remove that top layers of a VGG/RESNet model, fit our own layers on top. We did this for images in order to utilize the previous layers of those models since there is a general form of images. Like in those models, the earlier layers learn to detect edges which is needed for all image detection tasks.\n",
    "\n",
    "The same things also apply to embeddings. As we discussed previously, we are representing each word in some higher dimensional vector space. Turns out, people have already trained models on billions of tokens and stored their representations in those higher dimensions. We can simply use those for our purposes.\n",
    "\n",
    "For this notebook, we will be using the GloVe word embeddings developed at Stanford.\n",
    "\n",
    "Reference : https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "Reference : https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I have already downloaded the embeddeddings. Its now time to use them. The embeddings I downloaded contain embeddings for 50,100,150,and 200 dimensional space. We will be working with 50 dimensions for now.\n",
    "\n",
    "Each line in the glove file has the word at the beginning, followed by 'd' vectors representing its embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embeddings_glove = {}\n",
    "f = open(GLOVE_50_DIM)\n",
    "for line in f:\n",
    "    value = line.split()\n",
    "    word = value[0]\n",
    "    vec = value[1:]\n",
    "    embeddings_glove[word] = vec\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.418', '0.24968', '-0.41242', '0.1217', '0.34527', '-0.044457', '-0.49688', '-0.17862', '-0.00066023', '-0.6566', '0.27843', '-0.14767', '-0.55677', '0.14658', '-0.0095095', '0.011658', '0.10204', '-0.12792', '-0.8443', '-0.12181', '-0.016801', '-0.33279', '-0.1552', '-0.23131', '-0.19181', '-1.8823', '-0.76746', '0.099051', '-0.42125', '-0.19526', '4.0071', '-0.18594', '-0.52287', '-0.31681', '0.00059213', '0.0074449', '0.17778', '-0.15897', '0.012041', '-0.054223', '-0.29871', '-0.15749', '-0.34758', '-0.045637', '-0.44251', '0.18785', '0.0027849', '-0.18411', '-0.11514', '-0.78581']\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_glove['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, the indices of the words in our index2word dict and the order followed by glove is different. So we need to map them and create out embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix=np.zeros((VOCAB_SIZE, EMBEDDING_LEN_50))\n",
    "\n",
    "for i in range(1,len(embedding_matrix)):    #index2word starts with index 1\n",
    "    word = index2word[i]\n",
    "    if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word): #regex to see if word can be used as key for embeddings_glove\n",
    "        embedding_matrix[i] = embeddings_glove[word] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.217 ,  0.4652, -0.4676,  0.1008,  1.0135,  0.7484, -0.531 , -0.2626,  0.1681,  0.1318,\n",
       "       -0.2491, -0.4419, -0.2174,  0.51  ,  0.1345, -0.4314, -0.0312,  0.2067, -0.7814, -0.2015,\n",
       "       -0.0974,  0.1609, -0.6184, -0.185 , -0.1246, -2.2526, -0.2232,  0.5043,  0.3226,  0.1531,\n",
       "        3.9636, -0.7137, -0.6701,  0.2839,  0.2174,  0.1443,  0.2593,  0.2343,  0.4274, -0.4445,\n",
       "        0.1381,  0.3697, -0.6429,  0.0241, -0.0393, -0.2604,  0.1202, -0.0438,  0.4101,  0.1796])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are now ready to use these prebuilt weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_16 (Embedding)     (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 500, 64)           12864     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 500, 64)           16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               1600100   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,879,614\n",
      "Trainable params: 1,879,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, \\\n",
    "                input_length=SEQ_LEN, weights=[embedding_matrix], trainable=True)(inp)\n",
    "conv = Convolution1D(filters=64, kernel_size=4, padding='same', activation='relu')(emb)\n",
    "conv = Convolution1D(filters=64, kernel_size=4, padding='same', activation='relu')(conv)\n",
    "pool = MaxPooling1D(pool_size=2)(conv) \n",
    "x = Dropout(0.2)(pool)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "preds = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "pretrained_model = Model(inputs=inp, outputs=preds)\n",
    "pretrained_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 5s 274us/step - loss: 0.7607 - acc: 0.4971 - val_loss: 0.6932 - val_acc: 0.4936\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 5s 233us/step - loss: 0.6931 - acc: 0.5030 - val_loss: 0.6926 - val_acc: 0.4940\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.6925 - acc: 0.5039 - val_loss: 0.6924 - val_acc: 0.4930\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.6911 - acc: 0.5189 - val_loss: 0.6911 - val_acc: 0.5186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a43ba7fd0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/12\n",
      "20000/20000 [==============================] - 5s 242us/step - loss: 0.6860 - acc: 0.5408 - val_loss: 0.6800 - val_acc: 0.5916\n",
      "Epoch 2/12\n",
      "20000/20000 [==============================] - 5s 237us/step - loss: 0.6494 - acc: 0.6090 - val_loss: 0.6836 - val_acc: 0.5790\n",
      "Epoch 3/12\n",
      "20000/20000 [==============================] - 5s 237us/step - loss: 0.5647 - acc: 0.6709 - val_loss: 0.4741 - val_acc: 0.7950\n",
      "Epoch 4/12\n",
      "20000/20000 [==============================] - 5s 238us/step - loss: 0.4410 - acc: 0.7354 - val_loss: 0.4496 - val_acc: 0.7822\n",
      "Epoch 5/12\n",
      "20000/20000 [==============================] - 5s 238us/step - loss: 0.3812 - acc: 0.8456 - val_loss: 0.3433 - val_acc: 0.8492\n",
      "Epoch 6/12\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.3300 - acc: 0.8787 - val_loss: 0.3590 - val_acc: 0.8530\n",
      "Epoch 7/12\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.3120 - acc: 0.8833 - val_loss: 0.3330 - val_acc: 0.8646\n",
      "Epoch 8/12\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.2729 - acc: 0.9044 - val_loss: 0.6004 - val_acc: 0.7780\n",
      "Epoch 9/12\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.2983 - acc: 0.8883 - val_loss: 0.3270 - val_acc: 0.8728\n",
      "Epoch 10/12\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.2292 - acc: 0.9247 - val_loss: 0.3130 - val_acc: 0.8764\n",
      "Epoch 11/12\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.2153 - acc: 0.9322 - val_loss: 0.3396 - val_acc: 0.8726\n",
      "Epoch 12/12\n",
      "20000/20000 [==============================] - 5s 240us/step - loss: 0.1954 - acc: 0.9397 - val_loss: 0.3567 - val_acc: 0.8712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a453325c0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.optimizer.lr = 1e-4\n",
    "pretrained_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You might have noticed that we started with the embedding layer to be trainable. After that, we are making it not trainable.\n",
    "\n",
    "I dont know why but this gave better accuracies during experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model.layers[1].trainable= False\n",
    "pretrained_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 5s 242us/step - loss: 0.1830 - acc: 0.9452 - val_loss: 0.3429 - val_acc: 0.8764\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 4s 204us/step - loss: 0.1825 - acc: 0.9480 - val_loss: 0.3343 - val_acc: 0.8794\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1772 - acc: 0.9525 - val_loss: 0.3309 - val_acc: 0.8804\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1782 - acc: 0.9506 - val_loss: 0.3297 - val_acc: 0.8802\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1757 - acc: 0.9514 - val_loss: 0.3296 - val_acc: 0.8808\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1769 - acc: 0.9529 - val_loss: 0.3295 - val_acc: 0.8810\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1758 - acc: 0.9507 - val_loss: 0.3298 - val_acc: 0.8800\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1755 - acc: 0.9529 - val_loss: 0.3296 - val_acc: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a42401eb8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.optimizer.lr = 1e-6\n",
    "pretrained_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can see, we can use pre-trained word embeddings in our embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN --> LSTM and GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the recent and exciting findings have been the use of RNN (Recurrent Neural Networks) for text processing. RNNs' enable us to find temporal information present in the data. They help store information over time. \n",
    "\n",
    "Here we will be trying to different types of RNNs' - LSTMs' (Long-Short-Term-Memory) and GRUs'(Gated Recurrent Units)\n",
    "\n",
    "References : https://keras.io/layers/recurrent/\n",
    "\n",
    "A very good post about LSTM's and how they work is detailed in the following blog post : \n",
    "\n",
    "References : http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "NOTE : One thing which we will notice is that RNNs' in general take longer to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple LSTM\n",
    "\n",
    "First, let us try to use a very simple model using the LSTM layer. We will NOT be working with the pre-trained embeddings for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_18 (Embedding)     (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 310,602\n",
      "Trainable params: 310,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "lstm = LSTM(100)(emb)\n",
    "preds = Dense(2, activation = 'softmax')(lstm)\n",
    "\n",
    "simple_lstm_model = Model(inputs=inp, outputs=preds)\n",
    "simple_lstm_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "simple_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.6586 - acc: 0.5936 - val_loss: 0.6519 - val_acc: 0.5878\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 35s 2ms/step - loss: 0.6286 - acc: 0.6751 - val_loss: 0.6039 - val_acc: 0.7192\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 35s 2ms/step - loss: 0.5305 - acc: 0.7814 - val_loss: 0.4168 - val_acc: 0.8098\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 35s 2ms/step - loss: 0.3300 - acc: 0.8563 - val_loss: 0.3392 - val_acc: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a3cccbc50>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lstm_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.2620 - acc: 0.8954 - val_loss: 0.3349 - val_acc: 0.8518\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.2233 - acc: 0.9135 - val_loss: 0.3246 - val_acc: 0.8620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a3cba5630>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lstm_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.1884 - acc: 0.9322 - val_loss: 0.3362 - val_acc: 0.8772\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.1632 - acc: 0.9426 - val_loss: 0.3259 - val_acc: 0.8722\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.1493 - acc: 0.9479 - val_loss: 0.3675 - val_acc: 0.8562\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 35s 2ms/step - loss: 0.1667 - acc: 0.9371 - val_loss: 0.3470 - val_acc: 0.8678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a3cb699e8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lstm_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extremely simple LSTM gave us validation accuracies of almost 87%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Conv-LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also work with convolution and LSTM layers in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 500, 32)           6432      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 309,834\n",
      "Trainable params: 309,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "x = Convolution1D(filters=32,kernel_size=4,padding='same')(emb)\n",
    "x = MaxPooling1D(pool_size=(2))(x)\n",
    "lstm = LSTM(100, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "preds = Dense(2, activation = 'softmax')(lstm)\n",
    "\n",
    "conv_lstm_model = Model(inputs=inp, outputs=preds)\n",
    "conv_lstm_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "conv_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you look closely, we have used dropouts directly in the LSTM layer. The two dropouts used in the layer itself are : \n",
    "\n",
    "     dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n",
    "\n",
    "     recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.6455 - acc: 0.6290 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.3813 - acc: 0.8344 - val_loss: 0.3534 - val_acc: 0.8454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a3b4ddcf8>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lstm_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With this model, withing 2 epochs we have reached validation accuracies of almost 85%. Also, this trains faster due to the maxpooling which has halved the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.3079 - acc: 0.8720 - val_loss: 0.3652 - val_acc: 0.8344\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.2659 - acc: 0.8927 - val_loss: 0.3405 - val_acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a3b3d54a8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lstm_model.optimizer.lr = 1e-4\n",
    "conv_lstm_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In just a few epochs we have reached decent accuracies on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Simple GRU Model\n",
    "\n",
    "Creating a GRU based model is as simpel as simply replacing the LSTM layer above with the GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100)               45300     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 295,502\n",
      "Trainable params: 295,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "lstm = GRU(100)(emb)\n",
    "preds = Dense(2, activation = 'softmax')(lstm)\n",
    "\n",
    "simple_gru_model = Model(inputs=inp, outputs=preds)\n",
    "simple_gru_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "simple_gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.6459 - acc: 0.6219 - val_loss: 0.5371 - val_acc: 0.7508\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3820 - acc: 0.8353 - val_loss: 0.3466 - val_acc: 0.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a38f3ea58>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_gru_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.2536 - acc: 0.8981 - val_loss: 0.3207 - val_acc: 0.8632\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.2607 - acc: 0.8971 - val_loss: 0.3195 - val_acc: 0.8716\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.1928 - acc: 0.9268 - val_loss: 0.3214 - val_acc: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a393eb940>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_gru_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An extremely simple GRU model gave almost 87.2% accuracies on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Conv-GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 500, 32)           6432      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 100)               39900     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 296,534\n",
      "Trainable params: 296,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "x = Convolution1D(filters=32,kernel_size=4,padding='same')(emb)\n",
    "x = MaxPooling1D(pool_size=(2))(x)\n",
    "lstm = GRU(100, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "preds = Dense(2, activation = 'softmax')(lstm)\n",
    "\n",
    "conv_gru_model = Model(inputs=inp, outputs=preds)\n",
    "conv_gru_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "conv_gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 18s 915us/step - loss: 0.6341 - acc: 0.6323 - val_loss: 0.4751 - val_acc: 0.7758\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 17s 834us/step - loss: 0.3855 - acc: 0.8330 - val_loss: 0.3740 - val_acc: 0.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a3725fcc0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_gru_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 17s 842us/step - loss: 0.3178 - acc: 0.8679 - val_loss: 0.3503 - val_acc: 0.8530\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 17s 838us/step - loss: 0.2684 - acc: 0.8907 - val_loss: 0.4031 - val_acc: 0.8360\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 17s 838us/step - loss: 0.2491 - acc: 0.9006 - val_loss: 0.3735 - val_acc: 0.8404\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 17s 845us/step - loss: 0.2204 - acc: 0.9175 - val_loss: 0.3952 - val_acc: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a37090f98>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_gru_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Conv-Stacked-GRU Model\n",
    "\n",
    "Let us build a slightly more complex model with one GRU layer stacked on top of another, i.e. output of one GRU layer feeding into the next GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_26 (Embedding)     (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 500, 32)           6432      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 250, 100)          39900     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 100)               60300     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 356,834\n",
      "Trainable params: 356,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(SEQ_LEN,))\n",
    "emb = Embedding(VOCAB_SIZE, EMBEDDING_LEN_50, input_length=SEQ_LEN)(inp)\n",
    "x = Convolution1D(filters=32,kernel_size=4,padding='same')(emb)\n",
    "x = MaxPooling1D(pool_size=(2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = GRU(100, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)(x)\n",
    "x = GRU(100, dropout=0.4, recurrent_dropout=0.4)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "preds = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "conv_stacked_gru_model = Model(inputs=inp, outputs=preds)\n",
    "conv_stacked_gru_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "conv_stacked_gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 35s 2ms/step - loss: 0.6659 - acc: 0.5761 - val_loss: 0.5215 - val_acc: 0.7372\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.4341 - acc: 0.8087 - val_loss: 0.3984 - val_acc: 0.8168\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.3257 - acc: 0.8681 - val_loss: 0.3768 - val_acc: 0.8292\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.2901 - acc: 0.8858 - val_loss: 0.3528 - val_acc: 0.8524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a2b527cc0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stacked_gru_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/6\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.2621 - acc: 0.9005 - val_loss: 0.3604 - val_acc: 0.8460\n",
      "Epoch 2/6\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.3108 - acc: 0.8726 - val_loss: 0.3970 - val_acc: 0.8318\n",
      "Epoch 3/6\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.2459 - acc: 0.9049 - val_loss: 0.4037 - val_acc: 0.8368\n",
      "Epoch 4/6\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2269 - acc: 0.9134 - val_loss: 0.4039 - val_acc: 0.8480\n",
      "Epoch 5/6\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2076 - acc: 0.9216 - val_loss: 0.3875 - val_acc: 0.8436\n",
      "Epoch 6/6\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.2015 - acc: 0.9261 - val_loss: 0.4215 - val_acc: 0.8414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a2b213d68>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_stacked_gru_model.optimizer.lr = 1e-4\n",
    "conv_stacked_gru_model.fit(train,Y_train,validation_split=0.2,batch_size=512,epochs=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
